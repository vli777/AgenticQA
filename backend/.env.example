# Environment Variables for Railway Deployment
# Copy this file to .env and fill in your actual values

# Debug mode (set to "false" for production)
DEBUG=false

# API Keys
OPENAI_API_KEY=your_openai_api_key_here  # Optional: Only needed for text-embedding-3-small
PINECONE_API_KEY=your_pinecone_api_key_here
NVIDIA_API_KEY=your_nvidia_api_key_here  # REQUIRED: For hosted embeddings (free tier available)

# Pinecone Configuration
PINECONE_INDEX_NAME=test

# Vector Dimension (must match your Pinecone index dimension)
# Default: 2048 for nvidia/llama-3.2-nv-embedqa-1b-v2
# Only change if using a different embedding model with different output dimensions
# VECTOR_DIMENSION=2048

# CORS Origins (comma-separated list for production)
CORS_ORIGINS=https://your-frontend-domain.com,https://another-domain.com

# NVIDIA Reranker (Optional - system falls back to hybrid score sorting if unavailable)
# To check available models: https://build.nvidia.com/explore/retrieval
# Default: nvidia/llama-3.2-nv-rerankqa-1b-v2 (automatically used if NVIDIA_API_KEY is set)
# Leave unset to use default
# NVIDIA_RERANKER_MODEL=nvidia/llama-3.2-nv-rerankqa-1b-v2

# Semantic Tagging Configuration
# Semantic tagging is always enabled - LLM extracts domain-agnostic tags from all content
# Model for LLM-based tag extraction
LLM_TAG_MODEL=meta/llama-3.3-70b-instruct
LLM_TAG_COUNT=5  # Number of tags to extract per chunk

# Zero-shot classification (optional fallback - only used if SEMANTIC_TAG_LABELS defined)
# Requires HUGGINGFACE_API_KEY for zero-shot classification
# HUGGINGFACE_API_KEY=your_huggingface_api_key_here
# HUGGINGFACE_ZS_MODEL=facebook/bart-large-mnli
# SEMANTIC_TAG_LABELS=category1,category2,category3  # Optional domain-specific labels
# SEMANTIC_TAG_THRESHOLD=0.6  # Confidence threshold for zero-shot tags
SEMANTIC_TAG_BOOST=0.2  # Score boost multiplier for tag matches in search

